{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.2, output txt. To copy the txt to data.sql at java backend. \n",
    "\n",
    "The website we are scraping: https://open.bccampus.ca/browse-our-collection/find-open-textbooks/\n",
    "Total number of books: 382\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\artac\\anaconda3\\envs\\condaEx\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: use options instead of chrome_options\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "chrome_options = Options()\n",
    "#stops the browser from popping up when this program runs \n",
    "chrome_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(executable_path=\"chromedriver\", chrome_options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOGUE_LINK_1ST_HALF = 'https://open.bccampus.ca/browse-our-collection/find-open-textbooks/?start=' \n",
    "list_number = 0 \n",
    "CATALOGUE_LINK_2ND_HALF = '&subject=&contributor=&searchTerm=&keyword=' \n",
    "\n",
    "catalogue_all_links = [] \n",
    "#prepare links of catalogue to iterate through\n",
    "for i in range(0, 390, 10): \n",
    "    catalogue_all_links.append(CATALOGUE_LINK_1ST_HALF + str(i) + CATALOGUE_LINK_2ND_HALF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_links_of_all_books = [] \n",
    "BOOK_LINK_1ST_HALF = 'https://open.bccampus.ca/browse-our-collection/find-open-textbooks/'\n",
    "#iterate through all 38 pages of catalogues\n",
    "for link in catalogue_all_links:\n",
    "    driver.get(link)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    #get links of each books in the page\n",
    "    for link in soup.findAll('a', href=True):\n",
    "        if ('uuid' in link.attrs.get('href')): \n",
    "            list_of_links_of_all_books.append(BOOK_LINK_1ST_HALF + link.attrs.get('href'))\n",
    "\n",
    "#remove duplicates \n",
    "list_of_links_of_all_books = list(dict.fromkeys(list_of_links_of_all_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link 1 done\n",
      "link 2 done\n",
      "link 3 done\n",
      "link 4 done\n",
      "link 5 done\n",
      "link 6 done\n",
      "link 7 done\n",
      "link 8 done\n",
      "link 9 done\n",
      "link 10 done\n",
      "link 11 done\n",
      "link 12 done\n",
      "link 13 done\n",
      "link 14 done\n",
      "link 15 done\n",
      "link 16 done\n",
      "link 17 done\n",
      "link 18 done\n",
      "link 19 done\n",
      "link 20 done\n",
      "link 21 done\n",
      "link 22 done\n",
      "link 23 done\n",
      "link 24 done\n",
      "link 25 done\n",
      "link 26 done\n",
      "link 27 done\n",
      "link 28 done\n",
      "link 29 done\n",
      "link 30 done\n",
      "link 31 done\n",
      "link 32 done\n",
      "link 33 done\n",
      "link 34 done\n",
      "link 35 done\n",
      "link 36 done\n",
      "link 37 done\n",
      "link 38 done\n",
      "link 39 done\n",
      "link 40 done\n",
      "link 41 done\n",
      "link 42 done\n",
      "link 43 done\n",
      "link 44 done\n",
      "link 45 done\n",
      "link 46 done\n",
      "link 47 done\n",
      "link 48 done\n",
      "link 49 done\n",
      "link 50 done\n",
      "link 51 done\n",
      "link 52 done\n",
      "link 53 done\n",
      "link 54 done\n",
      "link 55 done\n",
      "link 56 done\n",
      "link 57 done\n",
      "link 58 done\n",
      "link 59 done\n",
      "link 60 done\n",
      "link 61 done\n",
      "link 62 done\n",
      "link 63 done\n",
      "link 64 done\n",
      "link 65 done\n",
      "link 66 done\n",
      "link 67 done\n",
      "link 68 done\n",
      "link 69 done\n",
      "link 70 done\n",
      "link 71 done\n",
      "link 72 done\n",
      "link 73 done\n",
      "link 74 done\n",
      "link 75 done\n",
      "link 76 done\n",
      "link 77 done\n",
      "link 78 done\n",
      "link 79 done\n",
      "link 80 done\n",
      "link 81 done\n",
      "link 82 done\n",
      "link 83 done\n",
      "link 84 done\n",
      "link 85 done\n",
      "link 86 done\n",
      "link 87 done\n",
      "link 88 done\n",
      "link 89 done\n",
      "link 90 done\n",
      "link 91 done\n",
      "link 92 done\n",
      "link 93 done\n",
      "link 94 done\n",
      "link 95 done\n",
      "link 96 done\n",
      "link 97 done\n",
      "link 98 done\n",
      "link 99 done\n",
      "link 100 done\n",
      "link 101 done\n",
      "link 102 done\n",
      "link 103 done\n",
      "link 104 done\n",
      "link 105 done\n",
      "link 106 done\n",
      "link 107 done\n",
      "link 108 done\n",
      "link 109 done\n",
      "link 110 done\n",
      "link 111 done\n",
      "link 112 done\n",
      "link 113 done\n",
      "link 114 done\n",
      "link 115 done\n",
      "link 116 done\n",
      "link 117 done\n",
      "link 118 done\n",
      "link 119 done\n",
      "link 120 done\n",
      "link 121 done\n",
      "link 122 done\n",
      "link 123 done\n",
      "link 124 done\n",
      "link 125 done\n",
      "link 126 done\n",
      "link 127 done\n",
      "link 128 done\n",
      "link 129 done\n",
      "link 130 done\n",
      "link 131 done\n",
      "link 132 done\n",
      "link 133 done\n",
      "link 134 done\n",
      "link 135 done\n",
      "link 136 done\n",
      "link 137 done\n",
      "link 138 done\n",
      "link 139 done\n",
      "link 140 done\n",
      "link 141 done\n",
      "link 142 done\n",
      "link 143 done\n",
      "link 144 done\n",
      "link 145 done\n",
      "link 146 done\n",
      "link 147 done\n",
      "link 148 done\n",
      "link 149 done\n",
      "link 150 done\n",
      "link 151 done\n",
      "link 152 done\n",
      "link 153 done\n",
      "link 154 done\n",
      "link 155 done\n",
      "link 156 done\n",
      "link 157 done\n",
      "link 158 done\n",
      "link 159 done\n",
      "link 160 done\n",
      "link 161 done\n",
      "link 162 done\n",
      "link 163 done\n",
      "link 164 done\n",
      "link 165 done\n",
      "link 166 done\n",
      "link 167 done\n",
      "link 168 done\n",
      "link 169 done\n",
      "link 170 done\n",
      "link 171 done\n",
      "link 172 done\n",
      "link 173 done\n",
      "link 174 done\n",
      "link 175 done\n",
      "link 176 done\n",
      "link 177 done\n",
      "link 178 done\n",
      "link 179 done\n",
      "link 180 done\n",
      "link 181 done\n",
      "link 182 done\n",
      "link 183 done\n",
      "link 184 done\n",
      "link 185 done\n",
      "link 186 done\n",
      "link 187 done\n",
      "link 188 done\n",
      "link 189 done\n",
      "link 190 done\n",
      "link 191 done\n",
      "link 192 done\n",
      "link 193 done\n",
      "link 194 done\n",
      "link 195 done\n",
      "link 196 done\n",
      "link 197 done\n",
      "link 198 done\n",
      "link 199 done\n",
      "link 200 done\n",
      "link 201 done\n",
      "link 202 done\n",
      "link 203 done\n",
      "link 204 done\n",
      "link 205 done\n",
      "link 206 done\n",
      "link 207 done\n",
      "link 208 done\n",
      "link 209 done\n",
      "link 210 done\n",
      "link 211 done\n",
      "link 212 done\n",
      "link 213 done\n",
      "link 214 done\n",
      "link 215 done\n",
      "link 216 done\n",
      "link 217 done\n",
      "link 218 done\n",
      "link 219 done\n",
      "link 220 done\n",
      "link 221 done\n",
      "link 222 done\n",
      "link 223 done\n",
      "link 224 done\n",
      "link 225 done\n",
      "link 226 done\n",
      "link 227 done\n",
      "link 228 done\n",
      "link 229 done\n",
      "link 230 done\n",
      "link 231 done\n",
      "link 232 done\n",
      "link 233 done\n",
      "link 234 done\n",
      "link 235 done\n",
      "link 236 done\n",
      "link 237 done\n",
      "link 238 done\n",
      "link 239 done\n",
      "link 240 done\n",
      "link 241 done\n",
      "link 242 done\n",
      "link 243 done\n",
      "link 244 done\n",
      "link 245 done\n",
      "link 246 done\n",
      "link 247 done\n",
      "link 248 done\n",
      "link 249 done\n",
      "link 250 done\n",
      "link 251 done\n",
      "link 252 done\n",
      "link 253 done\n",
      "link 254 done\n",
      "link 255 done\n",
      "link 256 done\n",
      "link 257 done\n",
      "link 258 done\n",
      "link 259 done\n",
      "link 260 done\n",
      "link 261 done\n",
      "link 262 done\n",
      "link 263 done\n",
      "link 264 done\n",
      "link 265 done\n",
      "link 266 done\n",
      "link 267 done\n",
      "link 268 done\n",
      "link 269 done\n",
      "link 270 done\n",
      "link 271 done\n",
      "link 272 done\n",
      "link 273 done\n",
      "link 274 done\n",
      "link 275 done\n",
      "link 276 done\n",
      "link 277 done\n",
      "link 278 done\n",
      "link 279 done\n",
      "link 280 done\n",
      "link 281 done\n",
      "link 282 done\n",
      "link 283 done\n",
      "link 284 done\n",
      "link 285 done\n",
      "link 286 done\n",
      "link 287 done\n",
      "link 288 done\n",
      "link 289 done\n",
      "link 290 done\n",
      "link 291 done\n",
      "link 292 done\n",
      "link 293 done\n",
      "link 294 done\n",
      "link 295 done\n",
      "link 296 done\n",
      "link 297 done\n",
      "link 298 done\n",
      "link 299 done\n",
      "link 300 done\n",
      "link 301 done\n",
      "link 302 done\n",
      "link 303 done\n",
      "link 304 done\n",
      "link 305 done\n",
      "link 306 done\n",
      "link 307 done\n",
      "link 308 done\n",
      "link 309 done\n",
      "link 310 done\n",
      "link 311 done\n",
      "link 312 done\n",
      "link 313 done\n",
      "link 314 done\n",
      "link 315 done\n",
      "link 316 done\n",
      "link 317 done\n",
      "link 318 done\n",
      "link 319 done\n",
      "link 320 done\n",
      "link 321 done\n",
      "link 322 done\n",
      "link 323 done\n",
      "link 324 done\n",
      "link 325 done\n",
      "link 326 done\n",
      "link 327 done\n",
      "link 328 done\n",
      "link 329 done\n",
      "link 330 done\n",
      "link 331 done\n",
      "link 332 done\n",
      "link 333 done\n",
      "link 334 done\n",
      "link 335 done\n",
      "link 336 done\n",
      "link 337 done\n",
      "link 338 done\n",
      "link 339 done\n",
      "link 340 done\n",
      "link 341 done\n",
      "link 342 done\n",
      "link 343 done\n",
      "link 344 done\n",
      "link 345 done\n",
      "link 346 done\n",
      "link 347 done\n",
      "link 348 done\n",
      "link 349 done\n",
      "link 350 done\n",
      "link 351 done\n",
      "link 352 done\n",
      "link 353 done\n",
      "link 354 done\n",
      "link 355 done\n",
      "link 356 done\n",
      "link 357 done\n",
      "link 358 done\n",
      "link 359 done\n",
      "link 360 done\n",
      "link 361 done\n",
      "link 362 done\n",
      "link 363 done\n",
      "link 364 done\n",
      "link 365 done\n",
      "link 366 done\n",
      "link 367 done\n",
      "link 368 done\n",
      "link 369 done\n",
      "link 370 done\n",
      "link 371 done\n",
      "link 372 done\n",
      "link 373 done\n",
      "link 374 done\n",
      "link 375 done\n",
      "link 376 done\n",
      "link 377 done\n",
      "link 378 done\n",
      "link 379 done\n",
      "link 380 done\n",
      "link 381 done\n",
      "link 382 done\n"
     ]
    }
   ],
   "source": [
    "def formaturl(url):\n",
    "    if not re.match('(?:http|ftp|https):', url):\n",
    "        return 'http:{}'.format(url)\n",
    "    return url\n",
    "\n",
    "def setGenre(link): \n",
    "    if ('Biological' or 'Astronomy' or 'Biology' or 'Chemistry' or 'Physics' or 'Science') in link: \n",
    "        return 'Biological/Physical Sciences'\n",
    "    elif ('Business' or 'Career' or 'College' or 'Accounting' or 'Business' or 'Commerce' or 'Entrepreneurship' or 'Finance' or 'Human' or 'Management' or 'Non-Profits') in link: \n",
    "        return 'Business'\n",
    "    elif ('Computer' or 'Algorithms' or 'Computer' or 'Databases' or 'Systems' or 'Web') in link: \n",
    "        return 'Computer Sciences' \n",
    "    elif ('Humanities' or 'English' or 'Gender' or 'History' or 'Lingustics' or 'Philosophy' or 'Spanish') in link:\n",
    "        return 'Humanities'\n",
    "    elif ('Math' or 'Algebra' or 'Calculus' or 'Statistics') in link: \n",
    "        return 'Math/Stats'\n",
    "\n",
    "    \n",
    "    else: \n",
    "        return 'Others'\n",
    "\n",
    "\n",
    "def escapeChars(string):\n",
    "    return string.translate(str.maketrans({\"'\": r\"\\'\",\n",
    "                                            \"\\r\": r\"\",\n",
    "                                            \"\\n\": r\"\"}))\n",
    "#                                       \"-\":  r\"\\-\",\n",
    "                                        #   \"]\":  r\"\\]\",\n",
    "                                        #   \"\\\\\": r\"\\\\\",\n",
    "                                        #   \"^\":  r\"\\^\",\n",
    "                                        #   \"$\":  r\"\\$\",\n",
    "                                        #   \"*\":  r\"\\*\",\n",
    "                                        #   \".\":  r\"\\.\"\n",
    "\n",
    "#build sql statement for data.sql \n",
    "sql = 'INSERT INTO `book` (`book_id`, `author`, `description`, `genre`, `link`, `photo`, `publish_date`, `title`) VALUES\\n'\n",
    "\n",
    "df = pd.DataFrame(columns =['book-id', 'title', 'genre', 'description'])\n",
    "#iterate through links to each book to get information of books and store them in the sql statement\n",
    "#sql statement requires manual cleaning at the end ',' \n",
    "number = 1 \n",
    "\n",
    "for link in list_of_links_of_all_books: \n",
    "    driver.get(link)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    #parse a webpage for book details \n",
    "    bookDetailsHTML = soup.find(attrs={'itemtype':'https://schema.org/Book'})\n",
    "\n",
    "    author = escapeChars(bookDetailsHTML.find(attrs={'itemprop':'author copyrightHolder'}).text)\n",
    "\n",
    "    description = escapeChars(bookDetailsHTML.find(attrs={'itemprop':'description'}).text)\n",
    "    description_split = re.findall(r'\\w+', description)[:15]\n",
    "    description = \" \".join(description_split)\n",
    "    description = description + \" ...\"\n",
    "\n",
    "    genre = setGenre(soup.find(attrs={'itemprop':\"about\"}).text)\n",
    "\n",
    "    photo_filename = 'book_' + str(number) + '.jpg'\n",
    "\n",
    "    #substring to keep date only\n",
    "    publish_date = bookDetailsHTML.find(attrs={'itemprop':'datePublished'}).attrs.get('content')[:10]\n",
    "\n",
    "    name = escapeChars(bookDetailsHTML.find(attrs={'itemprop':'name'}).text )\n",
    "\n",
    "\n",
    "    # #download image file. photo string is image filename. \n",
    "    # image_url = soup.find(attrs={'itemprop':'image'}).attrs.get('src')\n",
    "    # image_url = formaturl(image_url)\n",
    "    # img_data = requests.get(image_url).content\n",
    "    # with open('book_' + str(number) + '.jpg', 'wb') as handler:\n",
    "    #     handler.write(img_data)\n",
    "\n",
    "    #check genre from subject areas \n",
    "    # print('subject area text:' + soup.find(attrs={'itemprop':\"about\"}).text)\n",
    "    # print('genre appended:' + setGenre(soup.find(attrs={'itemprop':\"about\"}).text))\n",
    "\n",
    "    #(`book_id`, `author`, `description`, `genre`, `link`, `photo`, `publish_date`, `title`),\\n'\n",
    "    sql += '(' + str(number) + ','\n",
    "    sql += ' \\'' + author + '\\','\n",
    "    sql += ' \\'' + description + '\\','\n",
    "    sql += ' \\'' + genre + '\\','\n",
    "    sql += ' \\'' + link + '\\','\n",
    "    sql += ' \\'' + photo_filename + '\\','\n",
    "    sql += ' \\'' + publish_date + '\\','\n",
    "    sql += ' \\'' + name + '\\''\n",
    "    sql += '),\\n'\n",
    "\n",
    "    #save required data to excel for textbook recommendation\n",
    "    df = df.append({'book-id' : number, 'title' : name, 'genre' : genre, 'description' : description}, ignore_index=True)\n",
    "\n",
    "    print('link ' + str(number) + ' done') \n",
    "    number = number + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382\n"
     ]
    }
   ],
   "source": [
    "print(len(list_of_links_of_all_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sql.txt' , 'w', encoding=\"utf-8\") as f: \n",
    "    f.write(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book-id</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>University Physics - Volume 1 (OpenStax)</td>\n",
       "      <td>Biological/Physical Sciences</td>\n",
       "      <td>University Physics is a three volume collectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Conservation Biology in Sub-Saharan Africa</td>\n",
       "      <td>Biological/Physical Sciences</td>\n",
       "      <td>Easy to read this lucid and accessible textboo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Psychology of Language</td>\n",
       "      <td>Others</td>\n",
       "      <td>In this textbook students are introduced to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Adult Literacy Fundamental Mathematics: Book 1...</td>\n",
       "      <td>Others</td>\n",
       "      <td>This is book one in a six book series on funda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Introduction to Drafting and AutoCAD 2D</td>\n",
       "      <td>Others</td>\n",
       "      <td>Introduction to Drafting and AutoCAD 2D was wr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  book-id                                              title  \\\n",
       "0       1           University Physics - Volume 1 (OpenStax)   \n",
       "1       2         Conservation Biology in Sub-Saharan Africa   \n",
       "2       3                             Psychology of Language   \n",
       "3       4  Adult Literacy Fundamental Mathematics: Book 1...   \n",
       "4       5           Introduction to Drafting and AutoCAD 2D    \n",
       "\n",
       "                          genre  \\\n",
       "0  Biological/Physical Sciences   \n",
       "1  Biological/Physical Sciences   \n",
       "2                        Others   \n",
       "3                        Others   \n",
       "4                        Others   \n",
       "\n",
       "                                         description  \n",
       "0  University Physics is a three volume collectio...  \n",
       "1  Easy to read this lucid and accessible textboo...  \n",
       "2  In this textbook students are introduced to th...  \n",
       "3  This is book one in a six book series on funda...  \n",
       "4  Introduction to Drafting and AutoCAD 2D was wr...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('textBooksData.xlsx', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('condaEx')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ea5e66f9c02928b2640fa9342587de329d83cd6eea0f42abc5e664b6a2b230e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
